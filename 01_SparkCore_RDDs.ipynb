{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=gray>*Se informa que el presente documento es propiedad de Synergic Partners, S.L.U. Asimismo, su contenido tiene carácter confidencial o reservado. Este documento no puede ser reproducido, en su totalidad o parcialmente, ni mostrado a terceros, ni utilizarse para otros propósitos que los que han originado su entrega, sin el permiso previo de Synergic Partners. Synergic Partners no podrá ser considerada responsable de eventuales errores u omisiones en la edición del documento. Por la presente, usted queda notificado que cualquier forma de reproducción, copia y divulgación del presente documento y/o la información contenida en el mismo están estrictamente prohibidas.*</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=gray>Mayo 2017 | Tecnologías Big Data</font>\n",
    "\n",
    "# <font color=#003d5c>Apache Spark 1.6</font>\n",
    "\n",
    "## <font color=#003d5c>Spark Core: RDDs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color=#003d5c>Resilient Distributed Dataset (RDD)</font>\n",
    "\n",
    "Los **RDDs** son la abstracción de datos atómica de Apache Spark. Consisten en colecciones de objetos particionados y  distribuidos en un cluster. Los RDDs nos permiten escribir programas en términos de operaciones, *transformaciones*, y *acciones*, sobre datos distribuidos.\n",
    "\n",
    "#### <font color=#003d5c>Características</font>\n",
    "\n",
    "- **In-memory**. Los datos de un RDD se almacenan en memoria, tanto (tamaño y tiempo) como sea posible.\n",
    "- **Inmutable (read-only)**. Un RDD no cambia una vez creado. Al ser modificado usando transformaciones se genera un nuevo RDD.\n",
    "- **Lazy evaluated**. Los datos de un RDD no están disponibles hasta que se ejecuta una acción sobre ellos\n",
    "- **Procesamiento de datos en paralelo**\n",
    "- **Cacheables**. permite persistencia de los datos, como la memoria (preferiblemente, por defecto) o el disco (más lento)\n",
    "- **Tipados**. Los valores de un RDD tienen tipos (ejemplos: RDD[(Int, String)], RDD[Long], etc.)\n",
    "- **Particionados**. Datos distribuidos en los nodos del cluster\n",
    "\n",
    "#### <font color=#003d5c>Transformaciones</font>\n",
    "\n",
    "<font color=gray>Operación</font> | <font color=gray>Descripción</font>\n",
    "------------ | -------------\n",
    "**map(func)** | Devuelve un nuevo RDD, aplicando a cada elemento del original la función ‘func’\n",
    "**filter(func)**| Devuelve un nuevo RDD, seleccionando únicamente aquellos elementos que devuelven true a la función ‘func’\n",
    "**flatMap(func)**| Parecida a map, pero cada elemento de entrada puede ser mapeado a 0 o más elementos de salida (‘func’ devolverá entonces una secuencia en vez de un simple elemento)\n",
    "**distinct()**| Devuelve un nuevo RDD que contiene los elementos distintos del RDD original\n",
    "**groupByKey()**| Cuando se llama sobre un RDD formado por pares (K,V), devuelve un nuevo RDD con pares (K, Seq[V])\n",
    "**reduceByKey(func)**| Cuando se llama sobre un RDD formado por pares (K,V), devuelve un nuevo RDD con pares (K, V) en el que los para cada clave (K) son agregados en base a la función de agregación ‘func’\n",
    "**sortByKey([ascending])**| Cuando se llama sobre un RDD formado por pares (K,V) donde K implementa ‘Ordered’, devuelve un nuevo RDD con pares (K, V) ordenados por la clave (K) en orden ascendente o descendente según argumento\n",
    "**join(otherDataset)**| Cuando se llama sobre RDDs formados por pares (K, V) y (K, W), devuelve un nuevo RDD con pares (K, (V, W)) con todas las parejas de elementos para cada clave (K)\n",
    "\n",
    "#### <font color=#003d5c>Acciones</font>\n",
    "\n",
    "<font color=gray>Operación</font> | <font color=gray>Descripción</font>\n",
    "------------ | -------------\n",
    "**reduce(func)**| Agrega los elementos del RDD utilizando las función ‘func’ (toma 2 argumentos y devuelve 1). La función debe ser conmutativa y asociativa para poder ser calculado correctamente en paralelo\n",
    "**collect()**| Devuelve todos los elementos del RDD en un array (útil tras un filtro u otra operación que devuelve un subconjunto suficientemente pequeño de datos). Operación costosa.\n",
    "**count()**| Devuelve el número de elementos en el RDD\n",
    "**take(n)**| Devuelve un array con los ‘n’ primeros elementos del RDD\n",
    "**first()**| Devuelve el primer elemento del RDD (similar a take(1))\n",
    "**countByKey()**| (solo para RDDs con elementos de tipo (K, V)). Devuelve un objeto ‘Map’ de pares (K, Int) con el conteo de cada clave (K)\n",
    "    \n",
    "#### <font color=#003d5c>Persistencia</font>\n",
    "\n",
    "<font color=gray>Operación</font> | <font color=gray>Descripción</font>\n",
    "----------|------------\n",
    "**cache()**| Persistencia de RDD con el nivel de almacenamiento por defecto (MEMORY_ONLY).\n",
    "**persist()**| Permite establecer el nivel de almacenamiento para la persistencia de RDD. Sólo puede ser utilizado si el RDD no tiene previamente asignado un nivel de almacenamiento.  \n",
    "**getStorageLevel()**| Permite consultar el nivel de almacenamiento de un RDD\n",
    "**unpersist()**|Elimina la persistencia de RDD y remueve todos los bloques de este en memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color=#003d5c>Crear un RDDs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen tres formas básicas para crear un RDD:\n",
    "\n",
    "#### <font color=#003d5c>1. Paralelizando colecciones existentes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "  <strong>Nota:</strong> Para crear un RDD en Apache Spark es necesario instanciar el `SparkContext`. En nuestro caso no es necesario, porque el entorno interactivo del Jupyter instacia el objeto `sc` automáticamente.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4, 5] # lista de enteros\n",
    "\n",
    "# paralelizar 'data' utilizando SparkContext --> RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Datos paralelizados en RDD:\", rdd.collect() # recoger datos mediante accion 'collect()' --> list\n",
    "print type(rdd), \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=#003d5c>2. Transformando RDDs ya existentes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtener un RDD incrementando en una unidad los elementos de otro RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"RDD con datos incrementados (x+1): \", rdd_inc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=#003d5c>3. Leyendo datos desde ficheros en HDFS u otro sistema de almacenamiento soportado por Hadoop</font>\n",
    "\n",
    "Se utiliza el método `textFile()` del `SparkContext`. Por defecto, el método lee un fichero de texto desde HDFS, o del sistema local de ficheros (si está disponible en todos los nodos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = 'Baby_Names__Beginning_2007.csv'\n",
    "directory = os.path.join('/tmp/spark')\n",
    "filepath = os.path.join(directory,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para leer desde HDFS del cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspeccionamos el primer elemento del RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#666666>Ejercicio 1. Crear RDD</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuplas =[(1,4),(2,5),(3,6)]\n",
    "\n",
    "# Completa el código necesario para crear un RDD a partir de la lista de tuplas\n",
    "\n",
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mostramos por pantalla el contenido del RDD (hay que evitar hacerlo con grandes datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color=#003d5c>Operaciones RDDs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuplas = [(1,4),(2,5),(3,6)]\n",
    "rdd = sc.parallelize(tuplas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado el RDD podemos realizar operaciones sobre el mismo, enlazando transformaciones y acciones. Por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(rdd.map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elevamos al cuadrado cada elemento del RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "  <strong>Nota</strong> En Python la palabra clave `lambda` define una función anónima. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de funciónes anónimas, las transformaciones aceptan funciones regulares de Python. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def suma (x):\n",
    "    return sum(x)\n",
    "\n",
    "rdd.map(suma).collect() # La función map() aplica la función suma a cada fila del RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `flatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(rdd.flatMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformación para obtener una sola columna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformación `flatMap()` aplica una función sobre cada elemento del RDD y devuelve una secuencia de valores. Como las transformaciones en Spark son *lazy evaluated*, esta no se ejecuta hasta que se realiza un acción (en este caso la operación `collect()`). El resultado obtenido es una secuencia de valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `filter()`\n",
    "\n",
    "Filtrar valores numericos menores que uno dado (0.5) [0.05,0.2,0.3,0.7,0.9] --> [0.05,0.2,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([0.05,0.2,0.3,0.7,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `take()`\n",
    "\n",
    "Obtener los dos primeros elementos de un RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([0.05,0.2,0.3,0.7,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen otras operaciones que permiten extraer datos de un RDD, p.e.: `first()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([0.05,0.2,0.3,0.7,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"¿es igual take(1) y first()?\", rdd.take(1) == rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  <strong>!</strong> ¿Por qué son diferentes?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `reduce()`\n",
    "\n",
    "Sumar todos los elementos de una lista de numeros, agregandolos mediante la funcion 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add # es necesario importar la funcion 'add' (suma 2 numeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([0.05,0.2,0.3,0.7,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `takeOrdered()`\n",
    "\n",
    "Obtener los dos primeros elementos de un RDD tras ser ordenados ascendenemente/descendentemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,5,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Los dos elementos mayores son:\", max2\n",
    "print \"Los dos elementos menores son:\", min2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cache()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Storage Level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpersist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#666666>Ejercicio 2. Operaciones RDDs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un RDD a partir de una lista de enteros, y contar el número de elementos pares. Mostrar por pantalla los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4, 5] # lista de enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución aquí "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=#666666>Ejercicio 3. Operaciónes `map()` y `collect()`</font>\n",
    "\n",
    "Re-escalar un vector de valores numericos `[0.05,0.2,0.3,0.7,0.9] --> [5,20,30,70,90]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color=#003d5c>Pair RDD</font>\n",
    "\n",
    "Son un tipo especial de RDD, donde cada elemento es un par clave-valor. Las claves y valores pueden ser de cualquier tipo.\n",
    "\n",
    "- Se utilizan para algoritmos de tipo MapReduce\n",
    "- Tienen asociadas funciones extras como: `sort`, `join`, `count`, etc.\n",
    "- Se pueden crear a partir de funciones: `map`, `flatmap`, `keyBy`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "personas = ['Michael, ', 'Andy, 30', 'Justin, 19']\n",
    "\n",
    "rdd = sc.parallelize(personas)\n",
    "personasRDD = (rdd\n",
    "        .map(lambda x: x.split(\",\"))\n",
    "        .map(lambda x: [x[0], int(x[1].strip()) if x[1].strip() else None])\n",
    "        .keyBy(lambda x: x[0])\n",
    "        .mapValues(lambda x: x[1])\n",
    "        )\n",
    "personasRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "personasRDD.lookup('Andy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color=#666666>Ejercicio propuesto. WordCount con RDD</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a implementar una aplicación que calcula la frecuencia de palabras del texto de una de las obras más importantes de la literatura universal. Para ello vamos a seguir los siguientes pasos:\n",
    "\n",
    "1. Cargar los datos\n",
    "2. Normalizar el texto\n",
    "3. Extraer palabras\n",
    "4. Contar las palabras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Cargar los datos\n",
    "\n",
    "El texto se lee desde un fichero almacenado en HDFS para crear un RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para leer los datos desde HDFS\n",
    "filename = 'quijote.txt'\n",
    "rddQuijote = sc.textFile('/tmp/spark/' + filename) # crear RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print type(rddQuijote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ejercicio*: Muestra las primeras cinco lineas del texto usando la variable rddQuijote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Normalizar\n",
    "\n",
    "A continuación se realizan las operaciones necesarias para estandarizar el texto. estas tareas incluyen:\n",
    "\n",
    "- eliminar signos de puntuación, \n",
    "- símbolos foráneos,\n",
    "- espacios en blanco extras,\n",
    "- convertir el texto en minísculas, \n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sp: preserve\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "def norm(text):\n",
    "    text = normalize('NFKD', text).encode('ASCII', 'ignore')\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]',\"\",text).lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenga un `rddQuijoteStd` que contenga el texto normalizado a partir del RDD original. Además es necesario eliminar líneas en blanco extras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Extraer palabras de lineas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se obtiene un RDD normalizado y sin lineas en blanco, tenemos que extraer las palabras del texto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Eliminar *stop words*\n",
    "\n",
    "Ahora vamos a eliminar las palabras vacias (*stop words*), p.e.: que, un, de, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sp: preserve\n",
    "stopWordsFile = 'stopwords.txt' \n",
    "stopWords = sc.textFile('/tmp/spark/' + stopWordsFile)\n",
    "stopWords = sc.broadcast(stopWords.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Contar palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del RDD obtenido, ejecuta las transformaciones y acciones necesarias para obtener las palabras y sus frecuencias.\n",
    "\n",
    "*Hint: Crear un RDD donde cada elemento es un par (key,value), y luego aplicar la acción `reduceByKey()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Palabras más comunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra las 10 palabras más comunes en el texto.\n",
    "\n",
    "*Hint: Utilizar la acción `takeOrdered()` en lugar de `collect()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Escribe tu solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017 – Synergic Partners"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
